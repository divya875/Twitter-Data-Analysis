2019-09-11 19:57:05,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = vamsi/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang3-3.4.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.9.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.9.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsch-0.1.54.jar:/usr/local/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/avro-1.7.7.jar:/usr/local/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/usr/local/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/yarn/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 11.0.4
************************************************************/
2019-09-11 19:57:05,720 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-11 19:57:06,468 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/usr/local/hadoop_tmp/hdfs/datanode/
2019-09-11 19:57:06,626 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-11 19:57:06,770 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-09-11 19:57:06,770 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-09-11 19:57:06,778 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-09-11 19:57:06,780 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-09-11 19:57:06,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is vamsi
2019-09-11 19:57:06,783 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-09-11 19:57:06,783 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-09-11 19:57:06,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-09-11 19:57:06,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-09-11 19:57:06,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-09-11 19:57:06,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-09-11 19:57:06,919 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-11 19:57:06,929 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-11 19:57:06,966 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-09-11 19:57:06,975 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-11 19:57:06,979 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-09-11 19:57:06,979 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-11 19:57:06,979 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-11 19:57:06,999 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 41273
2019-09-11 19:57:07,000 INFO org.mortbay.log: jetty-6.1.26
2019-09-11 19:57:07,216 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:41273
2019-09-11 19:57:07,256 INFO io.netty.util.internal.PlatformDependent: Your platform does not provide complete low-level API for accessing direct buffers reliably. Unless explicitly requested, heap buffer will always be preferred to avoid potential system unstability.
2019-09-11 19:57:07,333 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-09-11 19:57:07,345 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-09-11 19:57:07,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = hduser
2019-09-11 19:57:07,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-09-11 19:57:07,437 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-09-11 19:57:07,452 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-09-11 19:57:07,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-09-11 19:57:07,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-09-11 19:57:07,604 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-09-11 19:57:07,623 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-09-11 19:57:07,639 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-09-11 19:57:07,639 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-09-11 19:57:07,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-09-11 19:57:07,959 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-09-11 19:57:07,979 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /usr/local/hadoop_tmp/hdfs/datanode/in_use.lock acquired by nodename 11554@vamsi
2019-09-11 19:57:07,980 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /usr/local/hadoop_tmp/hdfs/datanode is not formatted for namespace 1558390335. Formatting...
2019-09-11 19:57:07,981 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-92ae1d52-441f-4ca2-a766-5ae2586caf79 for directory /usr/local/hadoop_tmp/hdfs/datanode
2019-09-11 19:57:08,064 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1065220818-127.0.1.1-1568249781568
2019-09-11 19:57:08,064 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568
2019-09-11 19:57:08,066 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568 is not formatted for BP-1065220818-127.0.1.1-1568249781568. Formatting ...
2019-09-11 19:57:08,067 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1065220818-127.0.1.1-1568249781568 directory /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current
2019-09-11 19:57:08,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1558390335;bpid=BP-1065220818-127.0.1.1-1568249781568;lv=-57;nsInfo=lv=-63;cid=CID-dfff0f8e-4ab4-47af-a1ed-a4df13ecd9ae;nsid=1558390335;c=1568249781568;bpid=BP-1065220818-127.0.1.1-1568249781568;dnuuid=null
2019-09-11 19:57:08,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID ac111be7-e5e2-4739-a447-9a91e6526547
2019-09-11 19:57:08,138 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-92ae1d52-441f-4ca2-a766-5ae2586caf79
2019-09-11 19:57:08,138 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /usr/local/hadoop_tmp/hdfs/datanode/current, StorageType: DISK
2019-09-11 19:57:08,148 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-09-11 19:57:08,154 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /usr/local/hadoop_tmp/hdfs/datanode/current
2019-09-11 19:57:08,163 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /usr/local/hadoop_tmp/hdfs/datanode/current
2019-09-11 19:57:08,164 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1065220818-127.0.1.1-1568249781568
2019-09-11 19:57:08,165 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1065220818-127.0.1.1-1568249781568 on volume /usr/local/hadoop_tmp/hdfs/datanode/current...
2019-09-11 19:57:08,340 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1065220818-127.0.1.1-1568249781568 on /usr/local/hadoop_tmp/hdfs/datanode/current: 174ms
2019-09-11 19:57:08,341 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1065220818-127.0.1.1-1568249781568: 177ms
2019-09-11 19:57:08,343 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1065220818-127.0.1.1-1568249781568 on volume /usr/local/hadoop_tmp/hdfs/datanode/current...
2019-09-11 19:57:08,344 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/replicas doesn't exist 
2019-09-11 19:57:08,344 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1065220818-127.0.1.1-1568249781568 on volume /usr/local/hadoop_tmp/hdfs/datanode/current: 0ms
2019-09-11 19:57:08,344 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2019-09-11 19:57:08,346 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1065220818-127.0.1.1-1568249781568 on volume /usr/local/hadoop_tmp/hdfs/datanode
2019-09-11 19:57:08,347 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/usr/local/hadoop_tmp/hdfs/datanode, DS-92ae1d52-441f-4ca2-a766-5ae2586caf79): finished scanning block pool BP-1065220818-127.0.1.1-1568249781568
2019-09-11 19:57:08,356 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 9/12/19, 12:58 AM with interval of 21600000ms
2019-09-11 19:57:08,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1065220818-127.0.1.1-1568249781568 (Datanode Uuid ac111be7-e5e2-4739-a447-9a91e6526547) service to localhost/127.0.0.1:9000 beginning handshake with NN
2019-09-11 19:57:08,375 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/usr/local/hadoop_tmp/hdfs/datanode, DS-92ae1d52-441f-4ca2-a766-5ae2586caf79): no suitable block pools found to scan.  Waiting 1814399970 ms.
2019-09-11 19:57:08,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1065220818-127.0.1.1-1568249781568 (Datanode Uuid ac111be7-e5e2-4739-a447-9a91e6526547) service to localhost/127.0.0.1:9000 successfully registered with NN
2019-09-11 19:57:08,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-09-11 19:57:08,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xdfd50140cf9ddf61,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 52 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-09-11 19:57:08,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1065220818-127.0.1.1-1568249781568
2019-09-11 20:30:51,446 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741825_1001 src: /127.0.0.1:59934 dest: /127.0.0.1:50010
2019-09-11 20:30:51,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59934, dest: /127.0.0.1:50010, bytes: 103, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_465168229_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741825_1001, duration(ns): 27189917
2019-09-11 20:30:51,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2019-09-11 20:37:39,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741826_1002 src: /127.0.0.1:59958 dest: /127.0.0.1:50010
2019-09-11 20:37:39,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59958, dest: /127.0.0.1:50010, bytes: 303323, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_131421478_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741826_1002, duration(ns): 27893700
2019-09-11 20:37:39,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2019-09-11 20:37:43,491 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741826_1002 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741826 for deletion
2019-09-11 20:37:43,493 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1065220818-127.0.1.1-1568249781568 blk_1073741826_1002 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741826
2019-09-11 20:42:43,044 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741827_1003 src: /127.0.0.1:59976 dest: /127.0.0.1:50010
2019-09-11 20:42:43,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59976, dest: /127.0.0.1:50010, bytes: 303323, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-946214598_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741827_1003, duration(ns): 24503139
2019-09-11 20:42:43,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2019-09-11 20:42:43,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741828_1004 src: /127.0.0.1:59978 dest: /127.0.0.1:50010
2019-09-11 20:42:43,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59978, dest: /127.0.0.1:50010, bytes: 115, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-946214598_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741828_1004, duration(ns): 6619329
2019-09-11 20:42:43,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2019-09-11 20:42:43,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741829_1005 src: /127.0.0.1:59980 dest: /127.0.0.1:50010
2019-09-11 20:42:43,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59980, dest: /127.0.0.1:50010, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-946214598_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741829_1005, duration(ns): 6577705
2019-09-11 20:42:43,274 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2019-09-11 20:42:43,656 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741830_1006 src: /127.0.0.1:59982 dest: /127.0.0.1:50010
2019-09-11 20:42:43,673 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59982, dest: /127.0.0.1:50010, bytes: 169157, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-946214598_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741830_1006, duration(ns): 10329847
2019-09-11 20:42:43,673 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2019-09-11 20:42:53,184 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741831_1007 src: /127.0.0.1:59998 dest: /127.0.0.1:50010
2019-09-11 20:42:53,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:59998, dest: /127.0.0.1:50010, bytes: 196259, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-415762048_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741831_1007, duration(ns): 24209481
2019-09-11 20:42:53,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2019-09-11 20:42:59,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741832_1008 src: /127.0.0.1:60010 dest: /127.0.0.1:50010
2019-09-11 20:43:05,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741833_1009 src: /127.0.0.1:60020 dest: /127.0.0.1:50010
2019-09-11 20:43:05,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60020, dest: /127.0.0.1:50010, bytes: 119, op: HDFS_WRITE, cliID: DFSClient_attempt_1568249868484_0002_r_000000_0_1603547581_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741833_1009, duration(ns): 18768775
2019-09-11 20:43:05,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2019-09-11 20:43:05,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60010, dest: /127.0.0.1:50010, bytes: 33593, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-415762048_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741832_1008, duration(ns): 6584026246
2019-09-11 20:43:05,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2019-09-11 20:43:05,921 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741834_1010 src: /127.0.0.1:60022 dest: /127.0.0.1:50010
2019-09-11 20:43:05,943 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60022, dest: /127.0.0.1:50010, bytes: 349, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-415762048_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741834_1010, duration(ns): 11876810
2019-09-11 20:43:05,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2019-09-11 20:43:05,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741835_1011 src: /127.0.0.1:60026 dest: /127.0.0.1:50010
2019-09-11 20:43:06,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60026, dest: /127.0.0.1:50010, bytes: 33593, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-415762048_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741835_1011, duration(ns): 15905682
2019-09-11 20:43:06,006 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2019-09-11 20:43:06,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741836_1012 src: /127.0.0.1:60028 dest: /127.0.0.1:50010
2019-09-11 20:43:06,496 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60028, dest: /127.0.0.1:50010, bytes: 196259, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-415762048_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741836_1012, duration(ns): 18596580
2019-09-11 20:43:06,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2019-09-11 20:43:10,774 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741827_1003 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741827 for deletion
2019-09-11 20:43:10,775 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741828_1004 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741828 for deletion
2019-09-11 20:43:10,775 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741829_1005 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741829 for deletion
2019-09-11 20:43:10,775 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741830_1006 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741830 for deletion
2019-09-11 20:43:10,775 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741831_1007 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741831 for deletion
2019-09-11 20:43:10,775 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741832_1008 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741832 for deletion
2019-09-11 20:43:10,775 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1065220818-127.0.1.1-1568249781568 blk_1073741827_1003 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741827
2019-09-11 20:43:10,776 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1065220818-127.0.1.1-1568249781568 blk_1073741828_1004 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741828
2019-09-11 20:43:10,776 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1065220818-127.0.1.1-1568249781568 blk_1073741829_1005 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741829
2019-09-11 20:43:10,776 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1065220818-127.0.1.1-1568249781568 blk_1073741830_1006 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741830
2019-09-11 20:43:10,776 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1065220818-127.0.1.1-1568249781568 blk_1073741831_1007 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741831
2019-09-11 20:43:10,776 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1065220818-127.0.1.1-1568249781568 blk_1073741832_1008 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741832
2019-09-11 20:53:10,939 WARN org.apache.hadoop.hdfs.server.datanode.web.webhdfs.WebHdfsHandler: Error retrieving hostname: 
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.server.datanode.web.webhdfs.WebHdfsHandler$1.run(WebHdfsHandler.java:140)
	at org.apache.hadoop.hdfs.server.datanode.web.webhdfs.WebHdfsHandler$1.run(WebHdfsHandler.java:132)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)
	at org.apache.hadoop.hdfs.server.datanode.web.webhdfs.WebHdfsHandler.channelRead0(WebHdfsHandler.java:132)
	at org.apache.hadoop.hdfs.server.datanode.web.URLDispatcher.channelRead0(URLDispatcher.java:51)
	at org.apache.hadoop.hdfs.server.datanode.web.URLDispatcher.channelRead0(URLDispatcher.java:31)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:333)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:319)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:333)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:319)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:163)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:333)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:319)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:787)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:130)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137)
	at java.base/java.lang.Thread.run(Thread.java:834)
2019-09-11 20:53:10,945 INFO datanode.webhdfs: unknown GET /webhdfs/v1/user/input/sample.txt?op=OPEN&namenoderpcaddress=localhost:9000&offset=0 200
2019-09-11 20:53:22,680 WARN org.apache.hadoop.hdfs.server.datanode.web.webhdfs.WebHdfsHandler: Error retrieving hostname: 
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.server.datanode.web.webhdfs.WebHdfsHandler$1.run(WebHdfsHandler.java:140)
	at org.apache.hadoop.hdfs.server.datanode.web.webhdfs.WebHdfsHandler$1.run(WebHdfsHandler.java:132)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)
	at org.apache.hadoop.hdfs.server.datanode.web.webhdfs.WebHdfsHandler.channelRead0(WebHdfsHandler.java:132)
	at org.apache.hadoop.hdfs.server.datanode.web.URLDispatcher.channelRead0(URLDispatcher.java:51)
	at org.apache.hadoop.hdfs.server.datanode.web.URLDispatcher.channelRead0(URLDispatcher.java:31)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:333)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:319)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:333)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:319)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:163)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:333)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:319)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:787)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:130)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137)
	at java.base/java.lang.Thread.run(Thread.java:834)
2019-09-11 20:53:22,682 INFO datanode.webhdfs: unknown GET /webhdfs/v1/user/input/sample.txt?op=OPEN&namenoderpcaddress=localhost:9000&offset=0 200
2019-09-11 20:56:47,350 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "vamsi/127.0.1.1"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:824)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:788)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1453)
	at org.apache.hadoop.ipc.Client.call(Client.java:1363)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy17.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:514)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:645)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:841)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.io.EOFException
	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:397)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1812)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2019-09-11 20:56:51,353 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-09-11 20:56:52,295 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2019-09-11 20:56:52,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at vamsi/127.0.1.1
************************************************************/
2019-09-14 18:12:17,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = vamsi/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang3-3.4.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.9.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.9.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsch-0.1.54.jar:/usr/local/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/avro-1.7.7.jar:/usr/local/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/usr/local/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/yarn/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 11.0.4
************************************************************/
2019-09-14 18:12:17,469 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-14 18:12:19,767 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/usr/local/hadoop_tmp/hdfs/datanode/
2019-09-14 18:12:20,300 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-14 18:12:20,917 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-09-14 18:12:20,918 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-09-14 18:12:20,948 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-09-14 18:12:20,954 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-09-14 18:12:20,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is vamsi
2019-09-14 18:12:20,963 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-09-14 18:12:20,963 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-09-14 18:12:21,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-09-14 18:12:21,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-09-14 18:12:21,119 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-09-14 18:12:21,119 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-09-14 18:12:21,798 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-14 18:12:21,876 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-14 18:12:22,275 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-09-14 18:12:22,298 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-14 18:12:22,309 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-09-14 18:12:22,314 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-14 18:12:22,314 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-14 18:12:22,367 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 43993
2019-09-14 18:12:22,367 INFO org.mortbay.log: jetty-6.1.26
2019-09-14 18:12:23,621 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:43993
2019-09-14 18:12:23,945 INFO io.netty.util.internal.PlatformDependent: Your platform does not provide complete low-level API for accessing direct buffers reliably. Unless explicitly requested, heap buffer will always be preferred to avoid potential system unstability.
2019-09-14 18:12:24,376 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-09-14 18:12:24,390 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-09-14 18:12:24,541 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = hduser
2019-09-14 18:12:24,541 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-09-14 18:12:25,015 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-09-14 18:12:25,031 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-09-14 18:12:25,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-09-14 18:12:25,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-09-14 18:12:25,262 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-09-14 18:12:25,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-09-14 18:12:25,585 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-09-14 18:12:25,583 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-09-14 18:12:26,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-09-14 18:12:26,094 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-09-14 18:12:26,115 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /usr/local/hadoop_tmp/hdfs/datanode/in_use.lock acquired by nodename 2845@vamsi
2019-09-14 18:12:26,386 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1065220818-127.0.1.1-1568249781568
2019-09-14 18:12:26,386 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568
2019-09-14 18:12:26,457 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1558390335;bpid=BP-1065220818-127.0.1.1-1568249781568;lv=-57;nsInfo=lv=-63;cid=CID-dfff0f8e-4ab4-47af-a1ed-a4df13ecd9ae;nsid=1558390335;c=1568249781568;bpid=BP-1065220818-127.0.1.1-1568249781568;dnuuid=ac111be7-e5e2-4739-a447-9a91e6526547
2019-09-14 18:12:26,812 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-92ae1d52-441f-4ca2-a766-5ae2586caf79
2019-09-14 18:12:26,812 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /usr/local/hadoop_tmp/hdfs/datanode/current, StorageType: DISK
2019-09-14 18:12:26,818 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-09-14 18:12:26,884 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /usr/local/hadoop_tmp/hdfs/datanode/current
2019-09-14 18:12:26,905 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /usr/local/hadoop_tmp/hdfs/datanode/current
2019-09-14 18:12:26,906 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1065220818-127.0.1.1-1568249781568
2019-09-14 18:12:26,911 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1065220818-127.0.1.1-1568249781568 on volume /usr/local/hadoop_tmp/hdfs/datanode/current...
2019-09-14 18:12:27,132 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1065220818-127.0.1.1-1568249781568 on /usr/local/hadoop_tmp/hdfs/datanode/current: 220ms
2019-09-14 18:12:27,133 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1065220818-127.0.1.1-1568249781568: 226ms
2019-09-14 18:12:27,153 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1065220818-127.0.1.1-1568249781568 on volume /usr/local/hadoop_tmp/hdfs/datanode/current...
2019-09-14 18:12:27,153 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/replicas doesn't exist 
2019-09-14 18:12:27,157 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1065220818-127.0.1.1-1568249781568 on volume /usr/local/hadoop_tmp/hdfs/datanode/current: 4ms
2019-09-14 18:12:27,209 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 75ms
2019-09-14 18:12:27,666 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/usr/local/hadoop_tmp/hdfs/datanode, DS-92ae1d52-441f-4ca2-a766-5ae2586caf79): no suitable block pools found to scan.  Waiting 1561480679 ms.
2019-09-14 18:12:27,684 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 9/14/19, 11:25 PM with interval of 21600000ms
2019-09-14 18:12:27,688 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1065220818-127.0.1.1-1568249781568 (Datanode Uuid ac111be7-e5e2-4739-a447-9a91e6526547) service to localhost/127.0.0.1:9000 beginning handshake with NN
2019-09-14 18:12:27,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1065220818-127.0.1.1-1568249781568 (Datanode Uuid ac111be7-e5e2-4739-a447-9a91e6526547) service to localhost/127.0.0.1:9000 successfully registered with NN
2019-09-14 18:12:27,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-09-14 18:12:28,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xe01f1be82eec0c69,  containing 1 storage report(s), of which we sent 1. The reports had 5 total blocks and used 1 RPC(s). This took 4 msec to generate and 72 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-09-14 18:12:28,931 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1065220818-127.0.1.1-1568249781568
2019-09-14 19:04:41,289 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741837_1013 src: /127.0.0.1:60796 dest: /127.0.0.1:50010
2019-09-14 19:04:41,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60796, dest: /127.0.0.1:50010, bytes: 104629, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-193522720_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741837_1013, duration(ns): 18986719
2019-09-14 19:04:41,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2019-09-14 19:14:22,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741838_1014 src: /127.0.0.1:60824 dest: /127.0.0.1:50010
2019-09-14 19:14:22,106 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60824, dest: /127.0.0.1:50010, bytes: 303323, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1687635167_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741838_1014, duration(ns): 19218110
2019-09-14 19:14:22,106 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2019-09-14 19:14:24,807 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741838_1014 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741838 for deletion
2019-09-14 19:14:24,809 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1065220818-127.0.1.1-1568249781568 blk_1073741838_1014 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741838
2019-09-14 19:16:09,939 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741839_1015 src: /127.0.0.1:60834 dest: /127.0.0.1:50010
2019-09-14 19:16:09,965 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60834, dest: /127.0.0.1:50010, bytes: 303323, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1428177091_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741839_1015, duration(ns): 20415153
2019-09-14 19:16:09,966 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2019-09-14 19:16:10,147 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741840_1016 src: /127.0.0.1:60836 dest: /127.0.0.1:50010
2019-09-14 19:16:10,157 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60836, dest: /127.0.0.1:50010, bytes: 119, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1428177091_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741840_1016, duration(ns): 4068688
2019-09-14 19:16:10,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741840_1016, type=LAST_IN_PIPELINE terminating
2019-09-14 19:16:10,198 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741841_1017 src: /127.0.0.1:60838 dest: /127.0.0.1:50010
2019-09-14 19:16:10,222 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60838, dest: /127.0.0.1:50010, bytes: 22, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1428177091_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741841_1017, duration(ns): 19072908
2019-09-14 19:16:10,223 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741841_1017, type=LAST_IN_PIPELINE terminating
2019-09-14 19:16:10,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741842_1018 src: /127.0.0.1:60840 dest: /127.0.0.1:50010
2019-09-14 19:16:10,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60840, dest: /127.0.0.1:50010, bytes: 169160, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1428177091_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741842_1018, duration(ns): 28536654
2019-09-14 19:16:10,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741842_1018, type=LAST_IN_PIPELINE terminating
2019-09-14 19:16:20,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741843_1019 src: /127.0.0.1:60856 dest: /127.0.0.1:50010
2019-09-14 19:16:20,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60856, dest: /127.0.0.1:50010, bytes: 196262, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_997863237_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741843_1019, duration(ns): 22948086
2019-09-14 19:16:20,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741843_1019, type=LAST_IN_PIPELINE terminating
2019-09-14 19:16:26,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741844_1020 src: /127.0.0.1:60868 dest: /127.0.0.1:50010
2019-09-14 19:16:33,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741845_1021 src: /127.0.0.1:60878 dest: /127.0.0.1:50010
2019-09-14 19:16:33,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60878, dest: /127.0.0.1:50010, bytes: 16465, op: HDFS_WRITE, cliID: DFSClient_attempt_1568502788444_0002_r_000000_0_-1539484477_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741845_1021, duration(ns): 20145038
2019-09-14 19:16:33,085 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741845_1021, type=LAST_IN_PIPELINE terminating
2019-09-14 19:16:33,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60868, dest: /127.0.0.1:50010, bytes: 33786, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_997863237_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741844_1020, duration(ns): 6494013848
2019-09-14 19:16:33,458 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741844_1020, type=LAST_IN_PIPELINE terminating
2019-09-14 19:16:33,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741846_1022 src: /127.0.0.1:60880 dest: /127.0.0.1:50010
2019-09-14 19:16:33,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60880, dest: /127.0.0.1:50010, bytes: 349, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_997863237_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741846_1022, duration(ns): 7913141
2019-09-14 19:16:33,510 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741846_1022, type=LAST_IN_PIPELINE terminating
2019-09-14 19:16:33,582 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741847_1023 src: /127.0.0.1:60884 dest: /127.0.0.1:50010
2019-09-14 19:16:33,594 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60884, dest: /127.0.0.1:50010, bytes: 33786, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_997863237_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741847_1023, duration(ns): 10022782
2019-09-14 19:16:33,597 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741847_1023, type=LAST_IN_PIPELINE terminating
2019-09-14 19:16:34,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741848_1024 src: /127.0.0.1:60888 dest: /127.0.0.1:50010
2019-09-14 19:16:34,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:60888, dest: /127.0.0.1:50010, bytes: 196262, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_997863237_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741848_1024, duration(ns): 10790857
2019-09-14 19:16:34,084 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741848_1024, type=LAST_IN_PIPELINE terminating
2019-09-14 19:16:36,878 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741840_1016 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741840 for deletion
2019-09-14 19:16:36,879 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741841_1017 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741841 for deletion
2019-09-14 19:16:36,879 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741842_1018 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741842 for deletion
2019-09-14 19:16:36,879 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1065220818-127.0.1.1-1568249781568 blk_1073741840_1016 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741840
2019-09-14 19:16:36,880 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1065220818-127.0.1.1-1568249781568 blk_1073741841_1017 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741841
2019-09-14 19:16:36,879 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741843_1019 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741843 for deletion
2019-09-14 19:16:36,880 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741844_1020 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741844 for deletion
2019-09-14 19:16:36,880 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741839_1015 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741839 for deletion
2019-09-14 19:16:36,880 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1065220818-127.0.1.1-1568249781568 blk_1073741842_1018 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741842
2019-09-14 19:16:36,880 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1065220818-127.0.1.1-1568249781568 blk_1073741843_1019 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741843
2019-09-14 19:16:36,880 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1065220818-127.0.1.1-1568249781568 blk_1073741844_1020 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741844
2019-09-14 19:16:36,881 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1065220818-127.0.1.1-1568249781568 blk_1073741839_1015 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741839
2019-09-14 19:40:59,629 WARN org.apache.hadoop.hdfs.server.datanode.web.webhdfs.WebHdfsHandler: Error retrieving hostname: 
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.server.datanode.web.webhdfs.WebHdfsHandler$1.run(WebHdfsHandler.java:140)
	at org.apache.hadoop.hdfs.server.datanode.web.webhdfs.WebHdfsHandler$1.run(WebHdfsHandler.java:132)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)
	at org.apache.hadoop.hdfs.server.datanode.web.webhdfs.WebHdfsHandler.channelRead0(WebHdfsHandler.java:132)
	at org.apache.hadoop.hdfs.server.datanode.web.URLDispatcher.channelRead0(URLDispatcher.java:51)
	at org.apache.hadoop.hdfs.server.datanode.web.URLDispatcher.channelRead0(URLDispatcher.java:31)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:333)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:319)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:333)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:319)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:163)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:333)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:319)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:787)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:130)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137)
	at java.base/java.lang.Thread.run(Thread.java:834)
2019-09-14 19:40:59,633 INFO datanode.webhdfs: unknown GET /webhdfs/v1/user1/input1/hashtags.txt?op=OPEN&namenoderpcaddress=localhost:9000&length=32768&offset=0 200
2019-09-14 19:45:46,658 WARN org.apache.hadoop.hdfs.server.datanode.web.webhdfs.WebHdfsHandler: Error retrieving hostname: 
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.server.datanode.web.webhdfs.WebHdfsHandler$1.run(WebHdfsHandler.java:140)
	at org.apache.hadoop.hdfs.server.datanode.web.webhdfs.WebHdfsHandler$1.run(WebHdfsHandler.java:132)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)
	at org.apache.hadoop.hdfs.server.datanode.web.webhdfs.WebHdfsHandler.channelRead0(WebHdfsHandler.java:132)
	at org.apache.hadoop.hdfs.server.datanode.web.URLDispatcher.channelRead0(URLDispatcher.java:51)
	at org.apache.hadoop.hdfs.server.datanode.web.URLDispatcher.channelRead0(URLDispatcher.java:31)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:333)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:319)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:333)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:319)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:163)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:333)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:319)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:787)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:130)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137)
	at java.base/java.lang.Thread.run(Thread.java:834)
2019-09-14 19:45:46,660 INFO datanode.webhdfs: unknown GET /webhdfs/v1/user/hduser/output1/_SUCCESS?op=OPEN&namenoderpcaddress=localhost:9000&offset=0 200
2019-09-14 19:47:45,200 WARN org.apache.hadoop.hdfs.server.datanode.web.webhdfs.WebHdfsHandler: Error retrieving hostname: 
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.server.datanode.web.webhdfs.WebHdfsHandler$1.run(WebHdfsHandler.java:140)
	at org.apache.hadoop.hdfs.server.datanode.web.webhdfs.WebHdfsHandler$1.run(WebHdfsHandler.java:132)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)
	at org.apache.hadoop.hdfs.server.datanode.web.webhdfs.WebHdfsHandler.channelRead0(WebHdfsHandler.java:132)
	at org.apache.hadoop.hdfs.server.datanode.web.URLDispatcher.channelRead0(URLDispatcher.java:51)
	at org.apache.hadoop.hdfs.server.datanode.web.URLDispatcher.channelRead0(URLDispatcher.java:31)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:333)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:319)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:333)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:319)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:163)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:333)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:319)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:787)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:130)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137)
	at java.base/java.lang.Thread.run(Thread.java:834)
2019-09-14 19:47:45,202 INFO datanode.webhdfs: unknown GET /webhdfs/v1/user/hduser/output1/part-r-00000?op=OPEN&namenoderpcaddress=localhost:9000&offset=0 200
2019-09-14 22:35:05,744 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = vamsi/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.9.2
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/common/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/local/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang3-3.4.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/local/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/local/hadoop/share/hadoop/common/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/common/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/common/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/common/lib/json-smart-1.3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/usr/local/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/local/hadoop/share/hadoop/common/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/common/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/usr/local/hadoop/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/common/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/common/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.9.2.jar:/usr/local/hadoop/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/usr/local/hadoop/share/hadoop/common/hadoop-nfs-2.9.2.jar:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/usr/local/hadoop/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/usr/local/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn:/usr/local/hadoop/share/hadoop/yarn/lib/commons-cli-1.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsch-0.1.54.jar:/usr/local/hadoop/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsp-api-2.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jettison-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guava-11.0.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xmlenc-0.52.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/local/hadoop/share/hadoop/yarn/lib/activation-1.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/usr/local/hadoop/share/hadoop/yarn/lib/servlet-api-2.5.jar:/usr/local/hadoop/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/avro-1.7.7.jar:/usr/local/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-json-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-lang-2.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/usr/local/hadoop/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-codec-1.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-net-3.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-digester-1.8.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/usr/local/hadoop/share/hadoop/yarn/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/usr/local/hadoop/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-client-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/usr/local/hadoop/share/hadoop/yarn/lib/gson-2.2.4.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/usr/local/hadoop/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/usr/local/hadoop/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/usr/local/hadoop/share/hadoop/yarn/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/usr/local/hadoop/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/usr/local/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/asm-3.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/usr/local/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z
STARTUP_MSG:   java = 11.0.4
************************************************************/
2019-09-14 22:35:05,978 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2019-09-14 22:35:11,875 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/usr/local/hadoop_tmp/hdfs/datanode/
2019-09-14 22:35:12,390 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-09-14 22:35:13,309 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-09-14 22:35:13,310 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2019-09-14 22:35:13,380 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-09-14 22:35:13,391 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2019-09-14 22:35:13,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is vamsi
2019-09-14 22:35:13,414 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2019-09-14 22:35:13,414 WARN org.apache.hadoop.conf.Configuration: No unit for dfs.datanode.outliers.report.interval(1800000) assuming MILLISECONDS
2019-09-14 22:35:13,445 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2019-09-14 22:35:13,778 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2019-09-14 22:35:13,800 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2019-09-14 22:35:13,801 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2019-09-14 22:35:14,243 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2019-09-14 22:35:14,263 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-09-14 22:35:14,440 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2019-09-14 22:35:14,465 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-09-14 22:35:14,479 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2019-09-14 22:35:14,480 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-09-14 22:35:14,480 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-09-14 22:35:14,713 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 38771
2019-09-14 22:35:14,713 INFO org.mortbay.log: jetty-6.1.26
2019-09-14 22:35:15,747 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:38771
2019-09-14 22:35:15,921 INFO io.netty.util.internal.PlatformDependent: Your platform does not provide complete low-level API for accessing direct buffers reliably. Unless explicitly requested, heap buffer will always be preferred to avoid potential system unstability.
2019-09-14 22:35:16,298 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
2019-09-14 22:35:16,315 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2019-09-14 22:35:16,534 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = hduser
2019-09-14 22:35:16,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2019-09-14 22:35:16,792 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2019-09-14 22:35:16,838 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2019-09-14 22:35:17,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2019-09-14 22:35:17,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2019-09-14 22:35:17,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2019-09-14 22:35:17,526 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2019-09-14 22:35:17,571 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2019-09-14 22:35:17,583 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2019-09-14 22:35:19,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2019-09-14 22:35:19,126 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2019-09-14 22:35:19,286 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /usr/local/hadoop_tmp/hdfs/datanode/in_use.lock acquired by nodename 2440@vamsi
2019-09-14 22:35:19,603 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1065220818-127.0.1.1-1568249781568
2019-09-14 22:35:19,603 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568
2019-09-14 22:35:19,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1558390335;bpid=BP-1065220818-127.0.1.1-1568249781568;lv=-57;nsInfo=lv=-63;cid=CID-dfff0f8e-4ab4-47af-a1ed-a4df13ecd9ae;nsid=1558390335;c=1568249781568;bpid=BP-1065220818-127.0.1.1-1568249781568;dnuuid=ac111be7-e5e2-4739-a447-9a91e6526547
2019-09-14 22:35:19,948 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-92ae1d52-441f-4ca2-a766-5ae2586caf79
2019-09-14 22:35:19,948 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /usr/local/hadoop_tmp/hdfs/datanode/current, StorageType: DISK
2019-09-14 22:35:20,027 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2019-09-14 22:35:20,052 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /usr/local/hadoop_tmp/hdfs/datanode/current
2019-09-14 22:35:20,085 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /usr/local/hadoop_tmp/hdfs/datanode/current
2019-09-14 22:35:20,089 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1065220818-127.0.1.1-1568249781568
2019-09-14 22:35:20,095 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1065220818-127.0.1.1-1568249781568 on volume /usr/local/hadoop_tmp/hdfs/datanode/current...
2019-09-14 22:35:20,461 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1065220818-127.0.1.1-1568249781568 on /usr/local/hadoop_tmp/hdfs/datanode/current: 357ms
2019-09-14 22:35:20,462 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1065220818-127.0.1.1-1568249781568: 373ms
2019-09-14 22:35:20,485 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1065220818-127.0.1.1-1568249781568 on volume /usr/local/hadoop_tmp/hdfs/datanode/current...
2019-09-14 22:35:20,485 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/replicas doesn't exist 
2019-09-14 22:35:20,520 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1065220818-127.0.1.1-1568249781568 on volume /usr/local/hadoop_tmp/hdfs/datanode/current: 34ms
2019-09-14 22:35:20,521 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 55ms
2019-09-14 22:35:20,879 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/usr/local/hadoop_tmp/hdfs/datanode, DS-92ae1d52-441f-4ca2-a766-5ae2586caf79): no suitable block pools found to scan.  Waiting 1545707466 ms.
2019-09-14 22:35:21,008 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 9/14/19, 10:44 PM with interval of 21600000ms
2019-09-14 22:35:21,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1065220818-127.0.1.1-1568249781568 (Datanode Uuid ac111be7-e5e2-4739-a447-9a91e6526547) service to localhost/127.0.0.1:9000 beginning handshake with NN
2019-09-14 22:35:21,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1065220818-127.0.1.1-1568249781568 (Datanode Uuid ac111be7-e5e2-4739-a447-9a91e6526547) service to localhost/127.0.0.1:9000 successfully registered with NN
2019-09-14 22:35:21,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2019-09-14 22:35:22,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xa0b5fc80167d6b82,  containing 1 storage report(s), of which we sent 1. The reports had 10 total blocks and used 1 RPC(s). This took 16 msec to generate and 363 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2019-09-14 22:35:22,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1065220818-127.0.1.1-1568249781568
2019-09-14 22:44:02,025 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-1065220818-127.0.1.1-1568249781568 Total blocks: 10, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2019-09-14 22:54:01,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741849_1025 src: /127.0.0.1:42882 dest: /127.0.0.1:50010
2019-09-14 22:54:02,076 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:42882, dest: /127.0.0.1:50010, bytes: 614927, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1260044169_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741849_1025, duration(ns): 79163804
2019-09-14 22:54:02,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741849_1025, type=LAST_IN_PIPELINE terminating
2019-09-14 22:59:44,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741850_1026 src: /127.0.0.1:42902 dest: /127.0.0.1:50010
2019-09-14 22:59:45,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:42902, dest: /127.0.0.1:50010, bytes: 303323, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-358453745_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741850_1026, duration(ns): 63941031
2019-09-14 22:59:45,054 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741850_1026, type=LAST_IN_PIPELINE terminating
2019-09-14 22:59:45,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741851_1027 src: /127.0.0.1:42904 dest: /127.0.0.1:50010
2019-09-14 22:59:45,436 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:42904, dest: /127.0.0.1:50010, bytes: 115, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-358453745_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741851_1027, duration(ns): 25946997
2019-09-14 22:59:45,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741851_1027, type=LAST_IN_PIPELINE terminating
2019-09-14 22:59:45,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741852_1028 src: /127.0.0.1:42906 dest: /127.0.0.1:50010
2019-09-14 22:59:45,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:42906, dest: /127.0.0.1:50010, bytes: 22, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-358453745_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741852_1028, duration(ns): 12340466
2019-09-14 22:59:45,556 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741852_1028, type=LAST_IN_PIPELINE terminating
2019-09-14 22:59:46,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741853_1029 src: /127.0.0.1:42908 dest: /127.0.0.1:50010
2019-09-14 22:59:47,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:42908, dest: /127.0.0.1:50010, bytes: 169160, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-358453745_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741853_1029, duration(ns): 82569073
2019-09-14 22:59:47,011 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741853_1029, type=LAST_IN_PIPELINE terminating
2019-09-14 23:00:11,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741854_1030 src: /127.0.0.1:42926 dest: /127.0.0.1:50010
2019-09-14 23:00:11,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:42926, dest: /127.0.0.1:50010, bytes: 196262, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1343534526_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741854_1030, duration(ns): 60004322
2019-09-14 23:00:11,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741854_1030, type=LAST_IN_PIPELINE terminating
2019-09-14 23:00:24,470 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741855_1031 src: /127.0.0.1:42940 dest: /127.0.0.1:50010
2019-09-14 23:00:38,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741856_1032 src: /127.0.0.1:42952 dest: /127.0.0.1:50010
2019-09-14 23:00:39,005 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:42952, dest: /127.0.0.1:50010, bytes: 324204, op: HDFS_WRITE, cliID: DFSClient_attempt_1568518566620_0001_r_000000_0_145765086_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741856_1032, duration(ns): 53826728
2019-09-14 23:00:39,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741856_1032, type=LAST_IN_PIPELINE terminating
2019-09-14 23:00:39,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:42940, dest: /127.0.0.1:50010, bytes: 33815, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1343534526_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741855_1031, duration(ns): 15490664239
2019-09-14 23:00:39,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741855_1031, type=LAST_IN_PIPELINE terminating
2019-09-14 23:00:40,439 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741857_1033 src: /127.0.0.1:42956 dest: /127.0.0.1:50010
2019-09-14 23:00:40,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:42956, dest: /127.0.0.1:50010, bytes: 351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1343534526_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741857_1033, duration(ns): 25550296
2019-09-14 23:00:40,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741857_1033, type=LAST_IN_PIPELINE terminating
2019-09-14 23:00:40,624 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741858_1034 src: /127.0.0.1:42960 dest: /127.0.0.1:50010
2019-09-14 23:00:40,645 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:42960, dest: /127.0.0.1:50010, bytes: 33815, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1343534526_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741858_1034, duration(ns): 14679218
2019-09-14 23:00:40,646 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741858_1034, type=LAST_IN_PIPELINE terminating
2019-09-14 23:00:41,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1065220818-127.0.1.1-1568249781568:blk_1073741859_1035 src: /127.0.0.1:42962 dest: /127.0.0.1:50010
2019-09-14 23:00:41,197 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:42962, dest: /127.0.0.1:50010, bytes: 196262, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1343534526_1, offset: 0, srvID: ac111be7-e5e2-4739-a447-9a91e6526547, blockid: BP-1065220818-127.0.1.1-1568249781568:blk_1073741859_1035, duration(ns): 25492918
2019-09-14 23:00:41,200 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1065220818-127.0.1.1-1568249781568:blk_1073741859_1035, type=LAST_IN_PIPELINE terminating
2019-09-14 23:00:46,973 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741850_1026 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741850 for deletion
2019-09-14 23:00:46,976 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741851_1027 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741851 for deletion
2019-09-14 23:00:46,976 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741852_1028 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741852 for deletion
2019-09-14 23:00:46,976 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741853_1029 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741853 for deletion
2019-09-14 23:00:46,976 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741854_1030 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741854 for deletion
2019-09-14 23:00:46,976 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1065220818-127.0.1.1-1568249781568 blk_1073741850_1026 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741850
2019-09-14 23:00:46,977 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741855_1031 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741855 for deletion
2019-09-14 23:00:46,978 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1065220818-127.0.1.1-1568249781568 blk_1073741851_1027 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741851
2019-09-14 23:00:46,978 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1065220818-127.0.1.1-1568249781568 blk_1073741852_1028 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741852
2019-09-14 23:00:46,978 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1065220818-127.0.1.1-1568249781568 blk_1073741853_1029 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741853
2019-09-14 23:00:46,978 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1065220818-127.0.1.1-1568249781568 blk_1073741854_1030 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741854
2019-09-14 23:00:46,979 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1065220818-127.0.1.1-1568249781568 blk_1073741855_1031 file /usr/local/hadoop_tmp/hdfs/datanode/current/BP-1065220818-127.0.1.1-1568249781568/current/finalized/subdir0/subdir0/blk_1073741855
2019-09-14 23:10:33,436 WARN org.apache.hadoop.hdfs.server.datanode.web.webhdfs.WebHdfsHandler: Error retrieving hostname: 
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.server.datanode.web.webhdfs.WebHdfsHandler$1.run(WebHdfsHandler.java:140)
	at org.apache.hadoop.hdfs.server.datanode.web.webhdfs.WebHdfsHandler$1.run(WebHdfsHandler.java:132)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)
	at org.apache.hadoop.hdfs.server.datanode.web.webhdfs.WebHdfsHandler.channelRead0(WebHdfsHandler.java:132)
	at org.apache.hadoop.hdfs.server.datanode.web.URLDispatcher.channelRead0(URLDispatcher.java:51)
	at org.apache.hadoop.hdfs.server.datanode.web.URLDispatcher.channelRead0(URLDispatcher.java:31)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:333)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:319)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:333)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:319)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:163)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:333)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:319)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:787)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:130)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137)
	at java.base/java.lang.Thread.run(Thread.java:834)
2019-09-14 23:10:33,443 INFO datanode.webhdfs: unknown GET /webhdfs/v1/user2/input2/urls.txt?op=OPEN&namenoderpcaddress=localhost:9000&length=32768&offset=0 200
